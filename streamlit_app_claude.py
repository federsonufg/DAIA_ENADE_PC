import streamlit as st
import requests
import json
import os
import regex as re
import pandas as pd
import PyPDF2
from io import BytesIO
import time
from datetime import datetime
import hashlib

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="üìä ENADE CC 2017 - DAIA", 
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/seu-usuario/enade-analyzer',
        'Report a bug': "mailto:admin@exemplo.com",
        'About': "Sistema Integrado de An√°lise Pedag√≥gica com IA"
    }
)

# CSS customizado para melhorar a apar√™ncia
st.markdown("""
<style>
    .main-header {
        padding: 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
        text-align: center;
    }
    .metric-container {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #007acc;
    }
    .chat-message {
        background: #ffffff;
        border: 1px solid #e1e5e9;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .sidebar-info {
        background: #e8f4fd;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    .warning-box {
        background: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 6px;
        padding: 12px;
        margin: 10px 0;
    }
    .success-box {
        background: #d1f2eb;
        border: 1px solid #7dcea0;
        border-radius: 6px;
        padding: 12px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# T√≠tulo e descri√ß√£o aprimorados
st.markdown("""
<div class="main-header">
    <h1>üìä ENADE CC 2017 (DAIA)</h1>
    <h3>Sistema Integrado de An√°lise Pedag√≥gica com IA</h3>
    <p><em>Prova de Conceito - An√°lise Inteligente de Avalia√ß√µes Educacionais</em></p>
</div>
""", unsafe_allow_html=True)

# Inicializar estados da sess√£o
if 'historico' not in st.session_state:
    st.session_state.historico = []
if 'documentos_carregados' not in st.session_state:
    st.session_state.documentos_carregados = False
if 'total_perguntas' not in st.session_state:
    st.session_state.total_perguntas = 0
if 'sessao_id' not in st.session_state:
    st.session_state.sessao_id = hashlib.md5(str(time.time()).encode()).hexdigest()[:8]

# Fun√ß√£o melhorada para carregar documentos
@st.cache_resource
def load_all_documents():
    """Carrega e processa todos os documentos PDF dispon√≠veis"""
    docs = {}
    files = {
        "Prova": "2017 - Questoes.pdf",
        "Gabarito (QO)": "2017 - BCC - gb.pdf", 
        "Padr√µes de Resposta (QD)": "2017 - Padroes de Resposta.pdf"
    }
    
    full_text = ""
    arquivos_encontrados = []
    arquivos_faltando = []
    
    for name, path in files.items():
        if os.path.exists(path):
            try:
                with open(path, "rb") as f:
                    pdf = PyPDF2.PdfReader(f)
                    num_pages = len(pdf.pages)
                    text = f"\n\n--- DOCUMENTO: {name} ({num_pages} p√°ginas) ---\n\n"
                    
                    for i, page in enumerate(pdf.pages):
                        try:
                            page_text = page.extract_text()
                            if page_text.strip():  # S√≥ adiciona se tiver conte√∫do
                                text += f"[P√°gina {i+1}]\n{page_text}\n\n"
                        except Exception as e:
                            st.warning(f"Erro ao extrair p√°gina {i+1} de {name}: {e}")
                    
                    full_text += text + "\n\n"
                    arquivos_encontrados.append(f"{name} ({num_pages} p√°ginas)")
                    
            except Exception as e:
                st.error(f"Erro ao processar {path}: {e}")
                arquivos_faltando.append(f"{name} (erro: {e})")
        else:
            arquivos_faltando.append(f"{name} (n√£o encontrado)")
    
    return {
        'text': full_text[:150000],  # Limite para contexto
        'arquivos_ok': arquivos_encontrados,
        'arquivos_erro': arquivos_faltando,
        'total_chars': len(full_text)
    }

# Fun√ß√£o para chamar a OpenAI GPT-4 API
def gpt4_chat(messages, api_key, model="gpt-4", temperature=0.5, max_tokens=2000):
    """Chama a API da OpenAI GPT-4 com tratamento de erros melhorado"""
    endpoint = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "stream": True
    }
    
    try:
        response = requests.post(endpoint, headers=headers, json=payload, stream=True, timeout=60)
        
        if response.status_code != 200:
            error_detail = ""
            try:
                error_data = response.json()
                error_detail = error_data.get('error', {}).get('message', response.text)
            except:
                error_detail = response.text
            
            st.error(f"‚ùå Erro na API OpenAI ({response.status_code}): {error_detail}")
            return
        
        for line in response.iter_lines():
            if line:
                decoded_line = line.decode('utf-8')
                if decoded_line.startswith("data: "):
                    json_data = decoded_line[6:]
                    if json_data != "[DONE]":
                        try:
                            event_data = json.loads(json_data)
                            if "choices" in event_data and len(event_data["choices"]) > 0:
                                delta = event_data["choices"][0].get("delta", {})
                                if "content" in delta:
                                    yield delta["content"]
                        except json.JSONDecodeError:
                            continue
                            
    except requests.exceptions.Timeout:
        st.error("‚è∞ Timeout na API. Tente novamente com uma pergunta mais espec√≠fica.")
    except requests.exceptions.ConnectionError:
        st.error("üåê Erro de conex√£o. Verifique sua internet.")
    except Exception as e:
        st.error(f"‚ùå Erro inesperado: {str(e)}")

# Carregar documentos
with st.spinner("üîÑ Carregando documentos..."):
    dados_documentos = load_all_documents()
    st.session_state.documentos_carregados = True

# Sidebar melhorada
with st.sidebar:
    st.markdown("### üîë Configura√ß√£o da IA")
    
    api_key = st.text_input(
        "OpenAI API Key", 
        type="password", 
        help="Obtenha em platform.openai.com",
        placeholder="sk-..."
    )
    
    if api_key:
        st.markdown('<div class="success-box">‚úÖ API Key configurada</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="warning-box">‚ö†Ô∏è API Key necess√°ria para funcionar</div>', unsafe_allow_html=True)
    
    model = st.selectbox(
        "Modelo GPT", 
        options=["gpt-4", "gpt-4-turbo-preview", "gpt-3.5-turbo"], 
        index=0,
        help="gpt-4: melhor qualidade\ngpt-4-turbo: mais r√°pido\ngpt-3.5-turbo: mais econ√¥mico"
    )
    
    temperature = st.slider(
        "Criatividade", 
        0.0, 1.0, 0.3, 0.1,
        help="0.0 = mais preciso, 1.0 = mais criativo"
    )
    
    max_tokens = st.slider(
        "Tamanho da resposta", 
        100, 4096, 2000, 100,
        help="M√°ximo de tokens na resposta"
    )
    
    st.divider()
    
    # Status dos documentos
    st.markdown("### üìÑ Status dos Documentos")
    if dados_documentos['arquivos_ok']:
        st.markdown('<div class="success-box">', unsafe_allow_html=True)
        st.markdown("**‚úÖ Carregados com sucesso:**")
        for arquivo in dados_documentos['arquivos_ok']:
            st.markdown(f"‚Ä¢ {arquivo}")
        st.markdown('</div>', unsafe_allow_html=True)
    
    if dados_documentos['arquivos_erro']:
        st.markdown('<div class="warning-box">', unsafe_allow_html=True)
        st.markdown("**‚ö†Ô∏è Problemas encontrados:**")
        for arquivo in dados_documentos['arquivos_erro']:
            st.markdown(f"‚Ä¢ {arquivo}")
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Estat√≠sticas da sess√£o
    st.divider()
    st.markdown("### üìä Estat√≠sticas da Sess√£o")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Perguntas", st.session_state.total_perguntas)
    with col2:
        st.metric("Docs", len(dados_documentos['arquivos_ok']))
    
    st.caption(f"Sess√£o: {st.session_state.sessao_id}")
    st.caption(f"Contexto: {dados_documentos['total_chars']:,} chars")
    
    # Bot√µes de a√ß√£o
    st.divider()
    if st.button("üîç Gerar Resumo da Prova", use_container_width=True):
        st.session_state.gerar_resumo = True
    
    if st.button("üóëÔ∏è Limpar Hist√≥rico", use_container_width=True):
        st.session_state.historico = []
        st.session_state.total_perguntas = 0
        st.rerun()
    
    if st.button("üíæ Exportar Conversa", use_container_width=True):
        if st.session_state.historico:
            conversa_text = f"# Conversa ENADE CC 2017 - {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
            for role, msg in st.session_state.historico:
                conversa_text += f"**{role.upper()}:** {msg}\n\n---\n\n"
            st.download_button(
                "üì• Download Conversa",
                conversa_text,
                file_name=f"conversa_enade_{st.session_state.sessao_id}.md",
                mime="text/markdown",
                use_container_width=True
            )

# Abas principais - apenas Chat e Sobre
tab1, tab2 = st.tabs([
    "üß† Chat Inteligente", 
    "‚ÑπÔ∏è Sobre o Projeto"
])

with tab1:
    st.markdown("### üí¨ Converse com os Documentos da Prova")
    
    # Sugest√µes de perguntas
    if not st.session_state.historico:
        st.markdown("**üí° Perguntas sugeridas:**")
        sugestoes = [
            "Quantas quest√µes a prova possui e como est√£o distribu√≠das?",
            "Quais s√£o os principais temas abordados nas quest√µes de algoritmos?",
            "Analise as quest√µes discursivas e seus padr√µes de resposta",
            "Qual o n√≠vel de dificuldade geral da prova?",
            "Compare as quest√µes de forma√ß√£o geral vs espec√≠ficas"
        ]
        
        cols = st.columns(2)
        for i, sugestao in enumerate(sugestoes):
            with cols[i % 2]:
                if st.button(f"üí≠ {sugestao}", key=f"sug_{i}", use_container_width=True):
                    st.session_state.pergunta_sugerida = sugestao
    
    # Container para hist√≥rico de chat
    chat_container = st.container()
    
    with chat_container:
        for i, (role, mensagem) in enumerate(st.session_state.historico):
            with st.chat_message(role):
                st.markdown(mensagem)
                if role == "assistant":
                    # Bot√£o de feedback (simplificado)
                    col1, col2, col3 = st.columns([1, 1, 8])
                    with col1:
                        if st.button("üëç", key=f"like_{i}"):
                            st.toast("Obrigado pelo feedback!")
                    with col2:
                        if st.button("üëé", key=f"dislike_{i}"):
                            st.toast("Feedback registrado. Vamos melhorar!")
    
    # Entrada do usu√°rio (melhorada)
    pergunta_inicial = st.session_state.get('pergunta_sugerida', '')
    if pergunta_inicial:
        st.session_state.pergunta_sugerida = None
    
    if prompt := st.chat_input("Digite sua pergunta sobre a prova ENADE CC 2017...", key="chat_input"):
        if not api_key:
            st.error("üîë Por favor, configure sua API key da OpenAI na barra lateral")
            st.stop()
            
        # Incrementar contador
        st.session_state.total_perguntas += 1
        
        # Adicionar ao hist√≥rico
        st.session_state.historico.append(("user", prompt))
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Preparar contexto melhorado
        contexto_sistema = f"""
        Voc√™ √© um especialista em an√°lise do ENADE de Ci√™ncia da Computa√ß√£o 2017. 
        
        DOCUMENTOS DISPON√çVEIS:
        {dados_documentos['text'][:15000]}... [contexto completo carregado]
        
        INSTRU√á√ïES:
        - Responda com base APENAS nos documentos fornecidos
        - Seja preciso e educativo
        - Cite n√∫meros de quest√µes quando relevante  
        - Use formata√ß√£o markdown para melhor legibilidade
        - Se n√£o souber algo, seja honesto
        """
        
        messages = [
            {"role": "system", "content": contexto_sistema},
            {"role": "user", "content": f"Pergunta: {prompt}"}
        ]
        
        # Gerar resposta com streaming
        with st.chat_message("assistant"):
            resposta_container = st.empty()
            resposta_completa = ""
            
            start_time = time.time()
            
            try:
                with st.spinner("ü§î Analisando documentos..."):
                    for chunk in gpt4_chat(
                        messages=messages,
                        api_key=api_key,
                        model=model,
                        temperature=temperature,
                        max_tokens=max_tokens
                    ):
                        if chunk:
                            resposta_completa += chunk
                            resposta_container.markdown(resposta_completa + "‚ñå")
                
                # Resposta final sem cursor
                resposta_container.markdown(resposta_completa)
                
                # Adicionar ao hist√≥rico
                st.session_state.historico.append(("assistant", resposta_completa))
                
                # Mostrar tempo de resposta
                tempo_resposta = time.time() - start_time
                st.caption(f"‚è±Ô∏è Respondido em {tempo_resposta:.1f}s com {model}")
                
            except Exception as e:
                st.error(f"‚ùå Erro ao gerar resposta: {str(e)}")
    
    # Auto-processar pergunta sugerida
    elif pergunta_inicial and api_key:
        st.session_state.total_perguntas += 1
        st.session_state.historico.append(("user", pergunta_inicial))
        # Processo similar ao acima para pergunta sugerida
        st.rerun()

    # Gerar resumo autom√°tico se solicitado
    if st.session_state.get('gerar_resumo') and api_key:
        st.session_state.gerar_resumo = False
        
        with st.spinner("üìù Gerando an√°lise completa da prova..."):
            messages = [
                {
                    "role": "system", 
                    "content": f"""Voc√™ √© um especialista em an√°lise pedag√≥gica do ENADE. 
                    Com base nos documentos da prova ENADE CC 2017, gere um resumo estruturado e detalhado.
                    
                    DOCUMENTOS: {dados_documentos['text'][:12000]}"""
                },
                {
                    "role": "user", 
                    "content": """Gere uma an√°lise completa da prova com:
                    
                    ## üìä Vis√£o Geral
                    - Total de quest√µes e distribui√ß√£o
                    - Tipos de quest√µes (objetivas, discursivas)
                    
                    ## üéØ Principais Temas Abordados  
                    - √Åreas de conhecimento mais cobradas
                    - T√≥picos espec√≠ficos por quest√£o
                    
                    ## üìà An√°lise Pedag√≥gica
                    - N√≠vel de dificuldade geral
                    - Compet√™ncias avaliadas
                    - Pontos de destaque
                    
                    ## üí° Insights para Educadores
                    - √Åreas que merecem mais aten√ß√£o
                    - Sugest√µes para prepara√ß√£o
                    
                    Use markdown e seja detalhado mas objetivo."""
                }
            ]
            
            resposta_container = st.empty()
            resposta_resumo = ""
            
            for chunk in gpt4_chat(
                messages=messages,
                api_key=api_key,
                model=model,
                temperature=0.1,
                max_tokens=3000
            ):
                if chunk:
                    resposta_resumo += chunk
                    resposta_container.markdown(resposta_resumo + "‚ñå")
            
            resposta_container.markdown(resposta_resumo)
            st.session_state.historico.append(("assistant", resposta_resumo))
            st.success("‚úÖ Resumo gerado com sucesso!")

with tab2:
    st.markdown("### ‚ÑπÔ∏è Sobre o Sistema")
    
    st.markdown("""
    <div class="sidebar-info">
    <h4>üéØ Objetivo do Projeto</h4>
    <p>Este sistema foi desenvolvido para demonstrar como a IA pode auxiliar na an√°lise pedag√≥gica 
    de avalia√ß√µes educacionais, especificamente o ENADE de Ci√™ncia da Computa√ß√£o 2017.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Metodologia
    st.subheader("üî¨ Metodologia de An√°lise")
    
    metodologia_cols = st.columns(3)
    
    with metodologia_cols[0]:
        st.markdown("""
        **1. üìÑ Processamento de Documentos**
        - Extra√ß√£o autom√°tica de texto dos PDFs
        - Limpeza e estrutura√ß√£o do conte√∫do
        - Indexa√ß√£o por tipo de documento
        - Valida√ß√£o de integridade dos dados
        """)
    
    with metodologia_cols[1]:
        st.markdown("""
        **2. üß† An√°lise com IA**
        - Processamento de linguagem natural avan√ßado
        - An√°lise sem√¢ntica do conte√∫do
        - Identifica√ß√£o de padr√µes e temas
        - Gera√ß√£o de insights autom√°ticos
        """)
    
    with metodologia_cols[2]:
        st.markdown("""
        **3. üí¨ Interface Conversacional**
        - Chat inteligente em tempo real
        - Respostas contextualizadas
        - Hist√≥rico de conversas
        - Exporta√ß√£o de an√°lises
        """)
    
    # Tecnologias utilizadas
    st.subheader("üõ†Ô∏è Tecnologias Utilizadas")
    
    tech_cols = st.columns(2)
    
    with tech_cols[0]:
        st.markdown("""
        **Frontend & Interface:**
        - üé® **Streamlit** - Framework web para Python
        - üì± **CSS Customizado** - Estiliza√ß√£o responsiva
        - üìä **Pandas** - Manipula√ß√£o de dados
        - üîÑ **Session State** - Gerenciamento de estado
        """)
    
    with tech_cols[1]:
        st.markdown("""
        **IA & Processamento:**
        - ü§ñ **OpenAI GPT-4** - Modelo de linguagem de √∫ltima gera√ß√£o
        - üìÑ **PyPDF2** - Extra√ß√£o de texto de PDFs
        - üîç **Regex** - Processamento de texto
        - üíæ **Caching** - Otimiza√ß√£o de performance
        """)
    
    # Vantagens da abordagem
    st.subheader("‚ú® Vantagens da Abordagem Integrada")
    
    vantagens = [
        {"icon": "üîó", "title": "Contexto Completo", "desc": "An√°lise conjunta de prova, gabarito e padr√µes de resposta"},
        {"icon": "‚ö°", "title": "Respostas R√°pidas", "desc": "Chat interativo com streaming em tempo real"},
        {"icon": "üéØ", "title": "Precis√£o", "desc": "Respostas baseadas exclusivamente nos documentos oficiais"},
        {"icon": "üì±", "title": "Interface Intuitiva", "desc": "Design responsivo e f√°cil de usar"},
        {"icon": "üíæ", "title": "Exporta√ß√£o", "desc": "Download de conversas em formato Markdown"},
        {"icon": "üîÑ", "title": "Sess√£o Persistente", "desc": "Hist√≥rico mantido durante toda a sess√£o"}
    ]
    
    vantagem_cols = st.columns(2)
    for i, vantagem in enumerate(vantagens):
        with vantagem_cols[i % 2]:
            st.markdown(f"""
            <div style="border: 1px solid #e1e5e9; border-radius: 8px; padding: 1rem; margin: 0.5rem 0;">
                <h4>{vantagem['icon']} {vantagem['title']}</h4>
                <p>{vantagem['desc']}</p>
            </div>
            """, unsafe_allow_html=True)
    
    # Documentos inclu√≠dos
    st.subheader("üìÑ Documentos Analisados")
    
    st.markdown("""
    O sistema processa e analisa tr√™s documentos fundamentais do ENADE CC 2017:
    
    1. **üìù Prova Completa** - Todas as quest√µes objetivas e discursivas
    2. **‚úÖ Gabarito Oficial** - Respostas corretas das quest√µes objetivas (9-35)
    3. **üìã Padr√µes de Resposta** - Crit√©rios de avalia√ß√£o das quest√µes discursivas (D1-D5)
    """)
    
    # Fluxo de processamento
    st.subheader("üîÑ Fluxo de Processamento")
    
    st.mermaid("""
    graph TD
        A[üìÑ Documentos PDF] --> B[üîç Extra√ß√£o de Texto]
        B --> C[üßπ Limpeza e Estrutura√ß√£o]
        C --> D[üíæ Cache em Mem√≥ria]
        D --> E[üí¨ Interface de Chat]
        E --> F[ü§ñ OpenAI GPT-4]
        F --> G[üìù Resposta Streaming]
        G --> H[üíæ Hist√≥rico da Sess√£o]
        H --> I[üì• Exporta√ß√£o]
        
        style A fill:#e1f5fe
        style E fill:#f3e5f5
        style F fill:#fff3e0
        style I fill:#e8f5e8
    """)
    
    # Limita√ß√µes e trabalhos futuros
    st.subheader("‚ö†Ô∏è Limita√ß√µes Atuais")
    
    st.warning("""
    **Limita√ß√µes conhecidas:**
    - Depend√™ncia da qualidade do texto extra√≠do dos PDFs
    - Necessidade de API key da OpenAI (custo por uso)
    - An√°lise limitada aos tr√™s documentos fornecidos
    - Hist√≥rico perdido ao recarregar a p√°gina
    """)
    
    st.subheader("üöÄ Pr√≥ximos Passos")
    
    st.info("""
    **Melhorias planejadas:**
    - üìä Dashboard com an√°lise estruturada das quest√µes
    - üîç Sistema de busca avan√ßada nos documentos
    - üì± Upload din√¢mico de novos PDFs
    - üíæ Persist√™ncia de conversas em banco de dados
    - üéØ Compara√ß√£o entre diferentes edi√ß√µes do ENADE
    - üìà M√©tricas e analytics de uso
    """)
    
    # Informa√ß√µes t√©cnicas
    st.subheader("üîß Informa√ß√µes T√©cnicas")
    
    info_cols = st.columns(3)
    
    with info_cols[0]:
        st.markdown("""
        **Modelos de IA Dispon√≠veis:**
        - **GPT-4**: M√°xima qualidade e precis√£o
        - **GPT-4 Turbo**: Mais r√°pido, mesma qualidade
        - **GPT-3.5 Turbo**: Mais econ√¥mico
        """)
    
    with info_cols[1]:
        st.markdown("""
        **Performance:**
        - **Cache**: Documentos carregados uma vez
        - **Streaming**: Respostas em tempo real
        - **Timeout**: 60 segundos por consulta
        """)
    
    with info_cols[2]:
        st.markdown("""
        **Capacidades:**
        - **Contexto**: 150k caracteres m√°ximo
        - **Tokens**: At√© 4096 por resposta
        - **Sess√£o**: Isolada por usu√°rio
        """)
    
    # Contato e suporte
    st.divider()
    
    st.subheader("üìû Contato e Suporte")
    
    contact_cols = st.columns(3)
    
    with contact_cols[0]:
        st.markdown("""
        **üìß Suporte T√©cnico**
        - Email: admin@exemplo.com
        - Hor√°rio: 8h √†s 18h
        - Resposta: at√© 24h
        """)
    
    with contact_cols[1]:
        st.markdown("""
        **üêõ Reportar Bugs**
        - GitHub Issues
        - Email com logs
        - Descri√ß√£o detalhada
        """)
    
    with contact_cols[2]:
        st.markdown("""
        **üí° Sugest√µes**
        - Formul√°rio de feedback
        - Roadmap p√∫blico
        - Comunidade de usu√°rios
        """)
    
    # Cr√©ditos
    st.subheader("üë• Cr√©ditos")
    
    st.markdown("""
    **Desenvolvido por:** DAIA-INF  
    **Tecnologia IA:** OpenAI GPT-4  
    **Framework:** Streamlit  
    **Ano:** 2025  
    **Licen√ßa:** MIT  
    
    ---
    
    üí° **Este √© um projeto de prova de conceito** demonstrando o potencial da IA generativa 
    na an√°lise educacional. Os insights gerados devem ser validados por especialistas em educa√ß√£o.
    """)

# Rodap√© melhorado
st.divider()

footer_cols = st.columns([2, 1, 1])

with footer_cols[0]:
    st.markdown("""
    **Sistema Integrado ENADE CC 2017** | Desenvolvido com ‚ù§Ô∏è por **DAIA-INF**  
    Vers√£o 2.0 | Powered by OpenAI GPT-4 | Janeiro 2025
    """)

with footer_cols[1]:
    if st.button("üìä Ver Estat√≠sticas", key="stats_footer"):
        st.balloons()
        st.success(f"""
        üìà **Estat√≠sticas da Sess√£o:**
        - Perguntas realizadas: {st.session_state.total_perguntas}
        - Documentos carregados: {len(dados_documentos['arquivos_ok'])}
        - Caracteres processados: {dados_documentos['total_chars']:,}
        - ID da sess√£o: {st.session_state.sessao_id}
        """)

with footer_cols[2]:
    if st.button("üéâ Sobre", key="about_footer"):
        st.snow()
        st.info("""
        üöÄ **Sistema de An√°lise Pedag√≥gica com IA**
        
        Uma ferramenta inovadora que combina processamento de documentos, 
        intelig√™ncia artificial e interface conversacional para revolucionar 
        a an√°lise de avalia√ß√µes educacionais.
        """)

# Debug info (apenas para desenvolvimento - remover em produ√ß√£o)
if st.sidebar.checkbox("üêõ Debug Info", help="Informa√ß√µes t√©cnicas para desenvolvimento"):
    with st.sidebar.expander("Debug"):
        st.json({
            "session_id": st.session_state.sessao_id,
            "total_perguntas": st.session_state.total_perguntas,
            "page_views": getattr(st.session_state, 'page_views', 0),
            "docs_loaded": len(dados_documentos['arquivos_ok']),
            "context_size": dados_documentos['total_chars'],
            "historico_length": len(st.session_state.historico)
        })
           # "