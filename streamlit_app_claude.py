import streamlit as st
import requests
import json
import os
import regex as re
import pandas as pd
import PyPDF2
from io import BytesIO
import time
from datetime import datetime
import hashlib

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="ğŸ“Š ENADE CC 2017 - DAIA", 
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/seu-usuario/enade-analyzer',
        'Report a bug': "mailto:admin@exemplo.com",
        'About': "Sistema Integrado de AnÃ¡lise PedagÃ³gica com IA"
    }
)

# CSS customizado para melhorar a aparÃªncia
st.markdown("""
<style>
    .main-header {
        padding: 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
        text-align: center;
    }
    .metric-container {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #007acc;
    }
    .chat-message {
        background: #ffffff;
        border: 1px solid #e1e5e9;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .sidebar-info {
        background: #e8f4fd;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    .warning-box {
        background: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 6px;
        padding: 12px;
        margin: 10px 0;
    }
    .success-box {
        background: #d1f2eb;
        border: 1px solid #7dcea0;
        border-radius: 6px;
        padding: 12px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# TÃ­tulo e descriÃ§Ã£o aprimorados
st.markdown("""
<div class="main-header">
    <h1>ğŸ“Š ENADE CC 2017 (DAIA)</h1>
    <h3>Sistema Integrado de AnÃ¡lise PedagÃ³gica com IA</h3>
    <p><em>Prova de Conceito - AnÃ¡lise Inteligente de AvaliaÃ§Ãµes Educacionais</em></p>
</div>
""", unsafe_allow_html=True)

# Inicializar estados da sessÃ£o
if 'historico' not in st.session_state:
    st.session_state.historico = []
if 'documentos_carregados' not in st.session_state:
    st.session_state.documentos_carregados = False
if 'total_perguntas' not in st.session_state:
    st.session_state.total_perguntas = 0
if 'sessao_id' not in st.session_state:
    st.session_state.sessao_id = hashlib.md5(str(time.time()).encode()).hexdigest()[:8]

# FunÃ§Ã£o melhorada para carregar documentos
@st.cache_resource
def load_all_documents():
    """Carrega e processa todos os documentos PDF disponÃ­veis"""
    docs = {}
    files = {
        "Prova": "2017 - Questoes.pdf",
        "Gabarito (QO)": "2017 - BCC - gb.pdf", 
        "PadrÃµes de Resposta (QD)": "2017 - Padroes de Resposta.pdf"
    }
    
    full_text = ""
    arquivos_encontrados = []
    arquivos_faltando = []
    
    for name, path in files.items():
        if os.path.exists(path):
            try:
                with open(path, "rb") as f:
                    pdf = PyPDF2.PdfReader(f)
                    num_pages = len(pdf.pages)
                    text = f"\n\n--- DOCUMENTO: {name} ({num_pages} pÃ¡ginas) ---\n\n"
                    
                    for i, page in enumerate(pdf.pages):
                        try:
                            page_text = page.extract_text()
                            if page_text.strip():  # SÃ³ adiciona se tiver conteÃºdo
                                text += f"[PÃ¡gina {i+1}]\n{page_text}\n\n"
                        except Exception as e:
                            st.warning(f"Erro ao extrair pÃ¡gina {i+1} de {name}: {e}")
                    
                    full_text += text + "\n\n"
                    arquivos_encontrados.append(f"{name} ({num_pages} pÃ¡ginas)")
                    
            except Exception as e:
                st.error(f"Erro ao processar {path}: {e}")
                arquivos_faltando.append(f"{name} (erro: {e})")
        else:
            arquivos_faltando.append(f"{name} (nÃ£o encontrado)")
    
    return {
        'text': full_text[:150000],  # Limite para contexto
        'arquivos_ok': arquivos_encontrados,
        'arquivos_erro': arquivos_faltando,
        'total_chars': len(full_text)
    }

# FunÃ§Ã£o para chamar a OpenAI GPT-4 API
def gpt4_chat(messages, api_key, model="gpt-4", temperature=0.5, max_tokens=2000):
    """Chama a API da OpenAI GPT-4 com tratamento de erros melhorado"""
    endpoint = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "stream": True
    }
    
    try:
        response = requests.post(endpoint, headers=headers, json=payload, stream=True, timeout=60)
        
        if response.status_code != 200:
            error_detail = ""
            try:
                error_data = response.json()
                error_detail = error_data.get('error', {}).get('message', response.text)
            except:
                error_detail = response.text
            
            st.error(f"âŒ Erro na API OpenAI ({response.status_code}): {error_detail}")
            return
        
        for line in response.iter_lines():
            if line:
                decoded_line = line.decode('utf-8')
                if decoded_line.startswith("data: "):
                    json_data = decoded_line[6:]
                    if json_data != "[DONE]":
                        try:
                            event_data = json.loads(json_data)
                            if "choices" in event_data and len(event_data["choices"]) > 0:
                                delta = event_data["choices"][0].get("delta", {})
                                if "content" in delta:
                                    yield delta["content"]
                        except json.JSONDecodeError:
                            continue
                            
    except requests.exceptions.Timeout:
        st.error("â° Timeout na API. Tente novamente com uma pergunta mais especÃ­fica.")
    except requests.exceptions.ConnectionError:
        st.error("ğŸŒ Erro de conexÃ£o. Verifique sua internet.")
    except Exception as e:
        st.error(f"âŒ Erro inesperado: {str(e)}")

# Carregar documentos
with st.spinner("ğŸ”„ Carregando documentos..."):
    dados_documentos = load_all_documents()
    st.session_state.documentos_carregados = True

# Sidebar melhorada
with st.sidebar:
    st.markdown("### ğŸ”‘ ConfiguraÃ§Ã£o da IA")
    
    api_key = st.text_input(
        "OpenAI API Key", 
        type="password", 
        help="Obtenha em platform.openai.com",
        placeholder="sk-..."
    )
    
    if api_key:
        st.markdown('<div class="success-box">âœ… API Key configurada</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="warning-box">âš ï¸ API Key necessÃ¡ria para funcionar</div>', unsafe_allow_html=True)
    
    model = st.selectbox(
        "Modelo GPT", 
        options=["gpt-4", "gpt-4-turbo-preview", "gpt-3.5-turbo"], 
        index=0,
        help="gpt-4: melhor qualidade\ngpt-4-turbo: mais rÃ¡pido\ngpt-3.5-turbo: mais econÃ´mico"
    )
    
    temperature = st.slider(
        "Criatividade", 
        0.0, 1.0, 0.3, 0.1,
        help="0.0 = mais preciso, 1.0 = mais criativo"
    )
    
    max_tokens = st.slider(
        "Tamanho da resposta", 
        100, 4096, 2000, 100,
        help="MÃ¡ximo de tokens na resposta"
    )
    
    st.divider()
    
    # Status dos documentos
    st.markdown("### ğŸ“„ Status dos Documentos")
    if dados_documentos['arquivos_ok']:
        st.markdown('<div class="success-box">', unsafe_allow_html=True)
        st.markdown("**âœ… Carregados com sucesso:**")
        for arquivo in dados_documentos['arquivos_ok']:
            st.markdown(f"â€¢ {arquivo}")
        st.markdown('</div>', unsafe_allow_html=True)
    
    if dados_documentos['arquivos_erro']:
        st.markdown('<div class="warning-box">', unsafe_allow_html=True)
        st.markdown("**âš ï¸ Problemas encontrados:**")
        for arquivo in dados_documentos['arquivos_erro']:
            st.markdown(f"â€¢ {arquivo}")
        st.markdown('</div>', unsafe_allow_html=True)
    
    # EstatÃ­sticas da sessÃ£o
    st.divider()
    st.markdown("### ğŸ“Š EstatÃ­sticas da SessÃ£o")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Perguntas", st.session_state.total_perguntas)
    with col2:
        st.metric("Docs", len(dados_documentos['arquivos_ok']))
    
    st.caption(f"SessÃ£o: {st.session_state.sessao_id}")
    st.caption(f"Contexto: {dados_documentos['total_chars']:,} chars")
    
    # BotÃµes de aÃ§Ã£o
    st.divider()
    if st.button("ğŸ” Gerar Resumo da Prova", use_container_width=True):
        st.session_state.gerar_resumo = True
    
    if st.button("ğŸ—‘ï¸ Limpar HistÃ³rico", use_container_width=True):
        st.session_state.historico = []
        st.session_state.total_perguntas = 0
        st.rerun()
    
    if st.button("ğŸ’¾ Exportar Conversa", use_container_width=True):
        if st.session_state.historico:
            conversa_text = f"# Conversa ENADE CC 2017 - {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
            for role, msg in st.session_state.historico:
                conversa_text += f"**{role.upper()}:** {msg}\n\n---\n\n"
            st.download_button(
                "ğŸ“¥ Download Conversa",
                conversa_text,
                file_name=f"conversa_enade_{st.session_state.sessao_id}.md",
                mime="text/markdown",
                use_container_width=True
            )

# Abas principais - apenas Chat e Sobre
tab1, tab2 = st.tabs([
    "ğŸ§  Chat Inteligente", 
    "â„¹ï¸ Sobre o Projeto"
])

with tab1:
    st.markdown("### ğŸ’¬ Converse com os Documentos da Prova")
    
    # SugestÃµes de perguntas
    if not st.session_state.historico:
        st.markdown("**ğŸ’¡ Perguntas sugeridas:**")
        sugestoes = [
            "Quantas questÃµes a prova possui e como estÃ£o distribuÃ­das?",
            "Quais sÃ£o os principais temas abordados nas questÃµes de algoritmos?",
            "Analise as questÃµes discursivas e seus padrÃµes de resposta",
            "Qual o nÃ­vel de dificuldade geral da prova?",
            "Compare as questÃµes de formaÃ§Ã£o geral vs especÃ­ficas"
        ]
        
        cols = st.columns(2)
        for i, sugestao in enumerate(sugestoes):
            with cols[i % 2]:
                if st.button(f"ğŸ’­ {sugestao}", key=f"sug_{i}", use_container_width=True):
                    st.session_state.pergunta_sugerida = sugestao
    
    # Container para histÃ³rico de chat
    chat_container = st.container()
    
    with chat_container:
        for i, (role, mensagem) in enumerate(st.session_state.historico):
            with st.chat_message(role):
                st.markdown(mensagem)
                if role == "assistant":
                    # BotÃ£o de feedback (simplificado)
                    col1, col2, col3 = st.columns([1, 1, 8])
                    with col1:
                        if st.button("ğŸ‘", key=f"like_{i}"):
                            st.toast("Obrigado pelo feedback!")
                    with col2:
                        if st.button("ğŸ‘", key=f"dislike_{i}"):
                            st.toast("Feedback registrado. Vamos melhorar!")
    
    # Entrada do usuÃ¡rio (melhorada)
    pergunta_inicial = st.session_state.get('pergunta_sugerida', '')
    if pergunta_inicial:
        st.session_state.pergunta_sugerida = None
    
    if prompt := st.chat_input("Digite sua pergunta sobre a prova ENADE CC 2017...", key="chat_input"):
        if not api_key:
            st.error("ğŸ”‘ Por favor, configure sua API key da OpenAI na barra lateral")
            st.stop()
            
        # Incrementar contador
        st.session_state.total_perguntas += 1
        
        # Adicionar ao histÃ³rico
        st.session_state.historico.append(("user", prompt))
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Preparar contexto melhorado
        contexto_sistema = f"""
        VocÃª Ã© um especialista em anÃ¡lise do ENADE de CiÃªncia da ComputaÃ§Ã£o 2017. 
        
        DOCUMENTOS DISPONÃVEIS:
        {dados_documentos['text'][:15000]}... [contexto completo carregado]
        
        INSTRUÃ‡Ã•ES:
        - Responda com base APENAS nos documentos fornecidos
        - Seja preciso e educativo
        - Cite nÃºmeros de questÃµes quando relevante  
        - Use formataÃ§Ã£o markdown para melhor legibilidade
        - Se nÃ£o souber algo, seja honesto
        """
        
        messages = [
            {"role": "system", "content": contexto_sistema},
            {"role": "user", "content": f"Pergunta: {prompt}"}
        ]
        
        # Gerar resposta com streaming
        with st.chat_message("assistant"):
            resposta_container = st.empty()
            resposta_completa = ""
            
            start_time = time.time()
            
            try:
                with st.spinner("ğŸ¤” Analisando documentos..."):
                    for chunk in gpt4_chat(
                        messages=messages,
                        api_key=api_key,
                        model=model,
                        temperature=temperature,
                        max_tokens=max_tokens
                    ):
                        if chunk:
                            resposta_completa += chunk
                            resposta_container.markdown(resposta_completa + "â–Œ")
                
                # Resposta final sem cursor
                resposta_container.markdown(resposta_completa)
                
                # Adicionar ao histÃ³rico
                st.session_state.historico.append(("assistant", resposta_completa))
                
                # Mostrar tempo de resposta
                tempo_resposta = time.time() - start_time
                st.caption(f"â±ï¸ Respondido em {tempo_resposta:.1f}s com {model}")
                
            except Exception as e:
                st.error(f"âŒ Erro ao gerar resposta: {str(e)}")
    
    # Auto-processar pergunta sugerida
    elif pergunta_inicial and api_key:
        st.session_state.total_perguntas += 1
        st.session_state.historico.append(("user", pergunta_inicial))
        # Processo similar ao acima para pergunta sugerida
        st.rerun()

    # Gerar resumo automÃ¡tico se solicitado
    if st.session_state.get('gerar_resumo') and api_key:
        st.session_state.gerar_resumo = False
        
        with st.spinner("ğŸ“ Gerando anÃ¡lise completa da prova..."):
            messages = [
                {
                    "role": "system", 
                    "content": f"""VocÃª Ã© um especialista em anÃ¡lise pedagÃ³gica do ENADE. 
                    Com base nos documentos da prova ENADE CC 2017, gere um resumo estruturado e detalhado.
                    
                    DOCUMENTOS: {dados_documentos['text'][:12000]}"""
                },
                {
                    "role": "user", 
                    "content": """Gere uma anÃ¡lise completa da prova com:
                    
                    ## ğŸ“Š VisÃ£o Geral
                    - Total de questÃµes e distribuiÃ§Ã£o
                    - Tipos de questÃµes (objetivas, discursivas)
                    
                    ## ğŸ¯ Principais Temas Abordados  
                    - Ãreas de conhecimento mais cobradas
                    - TÃ³picos especÃ­ficos por questÃ£o
                    
                    ## ğŸ“ˆ AnÃ¡lise PedagÃ³gica
                    - NÃ­vel de dificuldade geral
                    - CompetÃªncias avaliadas
                    - Pontos de destaque
                    
                    ## ğŸ’¡ Insights para Educadores
                    - Ãreas que merecem mais atenÃ§Ã£o
                    - SugestÃµes para preparaÃ§Ã£o
                    
                    Use markdown e seja detalhado mas objetivo."""
                }
            ]
            
            resposta_container = st.empty()
            resposta_resumo = ""
            
            for chunk in gpt4_chat(
                messages=messages,
                api_key=api_key,
                model=model,
                temperature=0.1,
                max_tokens=3000
            ):
                if chunk:
                    resposta_resumo += chunk
                    resposta_container.markdown(resposta_resumo + "â–Œ")
            
            resposta_container.markdown(resposta_resumo)
            st.session_state.historico.append(("assistant", resposta_resumo))
            st.success("âœ… Resumo gerado com sucesso!")

with tab2:
    st.markdown("### â„¹ï¸ Sobre o Sistema")
    
    st.markdown("""
    <div class="sidebar-info">
    <h4>ğŸ¯ Objetivo do Projeto</h4>
    <p>Este sistema foi desenvolvido para demonstrar como a IA pode auxiliar na anÃ¡lise pedagÃ³gica 
    de avaliaÃ§Ãµes educacionais, especificamente o ENADE de CiÃªncia da ComputaÃ§Ã£o 2017.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Metodologia
    st.subheader("ğŸ”¬ Metodologia de AnÃ¡lise")
    
    metodologia_cols = st.columns(3)
    
    with metodologia_cols[0]:
        st.markdown("""
        **1. ğŸ“„ Processamento de Documentos**
        - ExtraÃ§Ã£o automÃ¡tica de texto dos PDFs
        - Limpeza e estruturaÃ§Ã£o do conteÃºdo
        - IndexaÃ§Ã£o por tipo de documento
        - ValidaÃ§Ã£o de integridade dos dados
        """)
    
    with metodologia_cols[1]:
        st.markdown("""
        **2. ğŸ§  AnÃ¡lise com IA**
        - Processamento de linguagem natural avanÃ§ado
        - AnÃ¡lise semÃ¢ntica do conteÃºdo
        - IdentificaÃ§Ã£o de padrÃµes e temas
        - GeraÃ§Ã£o de insights automÃ¡ticos
        """)
    
    with metodologia_cols[2]:
        st.markdown("""
        **3. ğŸ’¬ Interface Conversacional**
        - Chat inteligente em tempo real
        - Respostas contextualizadas
        - HistÃ³rico de conversas
        - ExportaÃ§Ã£o de anÃ¡lises
        """)
    
    # Tecnologias utilizadas
    st.subheader("ğŸ› ï¸ Tecnologias Utilizadas")
    
    tech_cols = st.columns(2)
    
    with tech_cols[0]:
        st.markdown("""
        **Frontend & Interface:**
        - ğŸ¨ **Streamlit** - Framework web para Python
        - ğŸ“± **CSS Customizado** - EstilizaÃ§Ã£o responsiva
        - ğŸ“Š **Pandas** - ManipulaÃ§Ã£o de dados
        - ğŸ”„ **Session State** - Gerenciamento de estado
        """)
    
    with tech_cols[1]:
        st.markdown("""
        **IA & Processamento:**
        - ğŸ¤– **OpenAI GPT-4** - Modelo de linguagem de Ãºltima geraÃ§Ã£o
        - ğŸ“„ **PyPDF2** - ExtraÃ§Ã£o de texto de PDFs
        - ğŸ” **Regex** - Processamento de texto
        - ğŸ’¾ **Caching** - OtimizaÃ§Ã£o de performance
        """)
    
    # Vantagens da abordagem
    st.subheader("âœ¨ Vantagens da Abordagem Integrada")
    
    vantagens = [
        {"icon": "ğŸ”—", "title": "Contexto Completo", "desc": "AnÃ¡lise conjunta de prova, gabarito e padrÃµes de resposta"},
        {"icon": "âš¡", "title": "Respostas RÃ¡pidas", "desc": "Chat interativo com streaming em tempo real"},
        {"icon": "ğŸ¯", "title": "PrecisÃ£o", "desc": "Respostas baseadas exclusivamente nos documentos oficiais"},
        {"icon": "ğŸ“±", "title": "Interface Intuitiva", "desc": "Design responsivo e fÃ¡cil de usar"},
        {"icon": "ğŸ’¾", "title": "ExportaÃ§Ã£o", "desc": "Download de conversas em formato Markdown"},
        {"icon": "ğŸ”„", "title": "SessÃ£o Persistente", "desc": "HistÃ³rico mantido durante toda a sessÃ£o"}
    ]
    
    vantagem_cols = st.columns(2)
    for i, vantagem in enumerate(vantagens):
        with vantagem_cols[i % 2]:
            st.markdown(f"""
            <div style="border: 1px solid #e1e5e9; border-radius: 8px; padding: 1rem; margin: 0.5rem 0;">
                <h4>{vantagem['icon']} {vantagem['title']}</h4>
                <p>{vantagem['desc']}</p>
            </div>
            """, unsafe_allow_html=True)
    
    # Documentos incluÃ­dos
    st.subheader("ğŸ“„ Documentos Analisados")
    
    st.markdown("""
    O sistema processa e analisa trÃªs documentos fundamentais do ENADE CC 2017:
    
    1. **ğŸ“ Prova Completa** - Todas as questÃµes objetivas e discursivas
    2. **âœ… Gabarito Oficial** - Respostas corretas das questÃµes objetivas (9-35)
    3. **ğŸ“‹ PadrÃµes de Resposta** - CritÃ©rios de avaliaÃ§Ã£o das questÃµes discursivas (D1-D5)
    """)
    
    # Fluxo de processamento
    st.subheader("ğŸ”„ Fluxo de Processamento")
    
    st.mermaid("""
    graph TD
        A[ğŸ“„ Documentos PDF] --> B[ğŸ” ExtraÃ§Ã£o de Texto]
        B --> C[ğŸ§¹ Limpeza e EstruturaÃ§Ã£o]
        C --> D[ğŸ’¾ Cache em MemÃ³ria]
        D --> E[ğŸ’¬ Interface de Chat]
        E --> F[ğŸ¤– OpenAI GPT-4]
        F --> G[ğŸ“ Resposta Streaming]
        G --> H[ğŸ’¾ HistÃ³rico da SessÃ£o]
        H --> I[ğŸ“¥ ExportaÃ§Ã£o]
        
        style A fill:#e1f5fe
        style E fill:#f3e5f5
        style F fill:#fff3e0
        style I fill:#e8f5e8
    """)
    
    # LimitaÃ§Ãµes e trabalhos futuros
    st.subheader("âš ï¸ LimitaÃ§Ãµes Atuais")
    
    st.warning("""
    **LimitaÃ§Ãµes conhecidas:**
    - DependÃªncia da qualidade do texto extraÃ­do dos PDFs
    - Necessidade de API key da OpenAI (custo por uso)
    - AnÃ¡lise limitada aos trÃªs documentos fornecidos
    - HistÃ³rico perdido ao recarregar a pÃ¡gina
    """)
    
    st.subheader("ğŸš€ PrÃ³ximos Passos")
    
    st.info("""
    **Melhorias planejadas:**
    - ğŸ“Š Dashboard com anÃ¡lise estruturada das questÃµes
    - ğŸ” Sistema de busca avanÃ§ada nos documentos
    - ğŸ“± Upload dinÃ¢mico de novos PDFs
    - ğŸ’¾ PersistÃªncia de conversas em banco de dados
    - ğŸ¯ ComparaÃ§Ã£o entre diferentes ediÃ§Ãµes do ENADE
    - ğŸ“ˆ MÃ©tricas e analytics de uso
    """)
    
    # InformaÃ§Ãµes tÃ©cnicas
    st.subheader("ğŸ”§ InformaÃ§Ãµes TÃ©cnicas")
    
    info_cols = st.columns(3)
    
    with info_cols[0]:
        st.markdown("""
        **Modelos de IA DisponÃ­veis:**
        - **GPT-4**: MÃ¡xima qualidade e precisÃ£o
        - **GPT-4 Turbo**: Mais rÃ¡pido, mesma qualidade
        - **GPT-3.5 Turbo**: Mais econÃ´mico
        """)
    
    with info_cols[1]:
        st.markdown("""
        **Performance:**
        - **Cache**: Documentos carregados uma vez
        - **Streaming**: Respostas em tempo real
        - **Timeout**: 60 segundos por consulta
        """)
    
    with info_cols[2]:
        st.markdown("""
        **Capacidades:**
        - **Contexto**: 150k caracteres mÃ¡ximo
        - **Tokens**: AtÃ© 4096 por resposta
        - **SessÃ£o**: Isolada por usuÃ¡rio
        """)
    
    # Contato e suporte
    st.divider()
    
    st.subheader("ğŸ“ Contato e Suporte")
    
    contact_cols = st.columns(3)
    
    with contact_cols[0]:
        st.markdown("""
        **ğŸ“§ Suporte TÃ©cnico**
        - Email: admin@exemplo.com
        - HorÃ¡rio: 8h Ã s 18h
        - Resposta: atÃ© 24h
        """)
    
    with contact_cols[1]:
        st.markdown("""
        **ğŸ› Reportar Bugs**
        - GitHub Issues
        - Email com logs
        - DescriÃ§Ã£o detalhada
        """)
    
    with contact_cols[2]:
        st.markdown("""
        **ğŸ’¡ SugestÃµes**
        - FormulÃ¡rio de feedback
        - Roadmap pÃºblico
        - Comunidade de usuÃ¡rios
        """)
    
    # CrÃ©ditos
    st.subheader("ğŸ‘¥ CrÃ©ditos")
    
    st.markdown("""
    **Desenvolvido por:** DAIA-INF  
    **Tecnologia IA:** OpenAI GPT-4  
    **Framework:** Streamlit  
    **Ano:** 2025  
    **LicenÃ§a:** MIT  
    
    ---
    
    ğŸ’¡ **Este Ã© um projeto de prova de conceito** demonstrando o potencial da IA generativa 
    na anÃ¡lise educacional. Os insights gerados devem ser validados por especialistas em educaÃ§Ã£o.
    """)

# RodapÃ© melhorado
st.divider()

footer_cols = st.columns([2, 1, 1])

with footer_cols[0]:
    st.markdown("""
    **Sistema Integrado ENADE CC 2017** | Desenvolvido com â¤ï¸ por **DAIA-INF**  
    VersÃ£o 2.0 | Powered by OpenAI GPT-4 | Janeiro 2025
    """)

with footer_cols[1]:
    if st.button("ğŸ“Š Ver EstatÃ­sticas", key="stats_footer"):
        st.balloons()
        st.success(f"""
        ğŸ“ˆ **EstatÃ­sticas da SessÃ£o:**
        - Perguntas realizadas: {st.session_state.total_perguntas}
        - Documentos carregados: {len(dados_documentos['arquivos_ok'])}
        - Caracteres processados: {dados_documentos['total_chars']:,}
        - ID da sessÃ£o: {st.session_state.sessao_id}
        """)

with footer_cols[2]:
    if st.button("ğŸ‰ Sobre", key="about_footer"):
        st.snow()
        st.info("""
        ğŸš€ **Sistema de AnÃ¡lise PedagÃ³gica com IA**
        
        Uma ferramenta inovadora que combina processamento de documentos, 
        inteligÃªncia artificial e interface conversacional para revolucionar 
        a anÃ¡lise de avaliaÃ§Ãµes educacionais.
        """)

# Debug info (apenas para desenvolvimento - remover em produÃ§Ã£o)
if st.sidebar.checkbox("ğŸ› Debug Info", help="InformaÃ§Ãµes tÃ©cnicas para desenvolvimento"):
    with st.sidebar.expander("Debug"):
        st.json({
            "session_id": st.session_state.sessao_id,
            "total_perguntas": st.session_state.total_perguntas,
            "page_views": getattr(st.session_state, 'page_views', 0),
            "docs_loaded": len(dados_documentos['arquivos_ok']),
            "context_size": dados_documentos['total_chars'],
            "historico_length": len(st.session_state.historico)
        })
           # "