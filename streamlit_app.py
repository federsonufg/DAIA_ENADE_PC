import streamlit as st
import requests
import json
import os
import regex as re
import pandas as pd
import PyPDF2
from io import BytesIO

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="üìä ENADE CC 2017 - DAIA", layout="wide")

# T√≠tulo e descri√ß√£o
st.title("üìä ENADE CC 2017 (DAIA)")
st.subheader("Sistema Integrado de An√°lise Pedag√≥gica com IA (Prova de Conceito)")
st.markdown("""
**Documentos inclu√≠dos:**
1. Prova ENADE CC 2017
2. Gabarito das Quest√µes Objetivas [9-35]
3. Padr√µes de Resposta das Quest√µes Discursivas [D1-D5]
""")


# Extra√ß√£o estruturada de quest√µes
@st.cache_resource
def extract_questions():
    questions = {}
    try:
        with open("2017 - BCC (OCR).pdf", "rb") as f:
            pdf = PyPDF2.PdfReader(f)
            full_text = ""
            
            # Concatenar todo o texto
            for page in pdf.pages:
                full_text += page.extract_text() + "\n"
            
            # Express√£o regular para encontrar quest√µes
            pattern = r'(?:QUEST√ÉO|Quest√£o) (\d{1,2})[\s\S]*?(?=(?:QUEST√ÉO|Quest√£o) \d{1,2}|$)'
            
            # Encontrar todas as quest√µes
            matches = re.finditer(pattern, full_text, re.IGNORECASE)
            
            for match in matches:
                q_number = match.group(1)
                q_text = match.group(0).strip()
                questions[q_number] = q_text
                
    except Exception as e:
        st.error(f"Erro na extra√ß√£o: {str(e)}")
    
    return questions

# Carregar quest√µes
questoes = extract_questions()


# Carregar todos os documentos combinados
@st.cache_resource
def load_all_documents():
    docs = {}
    files = {
        #"Prova": "2017 - BCC (OCR).pdf",
        "Gabarito (QO)": "2017 - BCC - gb.pdf",
        "Padr√µes de Resposta (QD)": "2017 - BCC - PV (OCR).pdf"
    }
    
    full_text = ""
    for name, path in files.items():
        if os.path.exists(path):
            with open(path, "rb") as f:
                pdf = PyPDF2.PdfReader(f)
                text = f"\n\n--- DOCUMENTO: {name} ---\n\n"
                text += "\n".join([page.extract_text() for page in pdf.pages])
                full_text += text + "\n\n"
        else:
            st.warning(f"Arquivo n√£o encontrado: {path}")
    return full_text[:150000]  # Limite para caber no contexto

# Carregar documentos uma vez no in√≠cio
documentos_completos = load_all_documents()

# Fun√ß√£o para chamar a DeepSeek API
def deepseek_chat(messages, api_key, model="deepseek-chat", temperature=0.5, max_tokens=2000):
    endpoint = "https://api.deepseek.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "stream": True
    }
    
    response = requests.post(endpoint, headers=headers, json=payload, stream=True)
    
    if response.status_code != 200:
        st.error(f"Erro na API: {response.status_code} - {response.text}")
        return None
    
    for line in response.iter_lines():
        if line:
            decoded_line = line.decode('utf-8')
            if decoded_line.startswith("data: "):
                json_data = decoded_line[6:]
                if json_data != "[DONE]":
                    try:
                        event_data = json.loads(json_data)
                        if "choices" in event_data and len(event_data["choices"]) > 0:
                            delta = event_data["choices"][0].get("delta", {})
                            if "content" in delta:
                                yield delta["content"]
                    except json.JSONDecodeError:
                        pass

# Interface principal
with st.sidebar:
    st.header("üîë Configura√ß√£o")
    api_key = st.text_input("DeepSeek API Key", type="password", help="Obtenha em platform.deepseek.com")
    model = st.selectbox("Modelo", options=["deepseek-chat", "deepseek-coder"], index=0)
    temperature = st.slider("Criatividade (temperature)", 0.0, 1.0, 0.3)
    max_tokens = st.slider("M√°ximo de tokens", 100, 4096, 2000)
    
        
    st.divider()
    if st.button("üîç Gerar Resumo da Prova", use_container_width=True):
        st.session_state.gerar_resumo = True

# Abas principais
tab1, tab2, tab3 = st.tabs(["üß† Chat com as Quest√µes da Prova", "üìä An√°lise Estruturada", "‚ÑπÔ∏è Sobre o Projeto"])

with tab1:
    if 'historico' not in st.session_state:
        st.session_state.historico = []
    
    # Exibir hist√≥rico
    for role, mensagem in st.session_state.historico:
        with st.chat_message(role):
            st.markdown(mensagem)
    
    # Entrada do usu√°rio
    if prompt := st.chat_input("Fa√ßa sua pergunta sobre a prova..."):
        if not api_key:
            st.warning("Por favor, insira sua API key da DeepSeek")
            st.stop()
            
        # Adicionar ao hist√≥rico
        st.session_state.historico.append(("user", prompt))
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Montar contexto completo
        contexto = f"""
        CONTEXTO COMPLETO DA PROVA ENADE CC 2017:
        {documentos_completos[:12000], questoes}... [documento completo carregado]
        """
        
        # Montar mensagens para a DeepSeek
        messages = [
            {
                "role": "system", 
                "content": "Voc√™ √© um especialista em an√°lise do ENADE de Ci√™ncia da Computa√ß√£o. "
                           "Responda com base nas quest√µes da prova, do gabarito e dos padr√µes de resposta combinados."
            },
            {
                "role": "user", 
                "content": f"Documenta√ß√£o completa carregada. Pergunta: {prompt}"
            }
        ]
        
        # Chamar DeepSeek
        try:
            resposta_parcial = ""
            container = st.empty()
            with st.chat_message("assistant"):
                for chunk in deepseek_chat(
                    messages=messages,
                    api_key=api_key,
                    model=model,
                    temperature=temperature,
                    max_tokens=max_tokens
                ):
                    if chunk:
                        resposta_parcial += chunk
                        container.markdown(resposta_parcial + "‚ñå")
            
            container.markdown(resposta_parcial)
            st.session_state.historico.append(("assistant", resposta_parcial))
                
        except Exception as e:
            st.error(f"Erro na gera√ß√£o: {str(e)}")
            
    # Gerar resumo autom√°tico se solicitado
    if st.session_state.get('gerar_resumo'):
        with st.spinner("Gerando resumo da prova..."):
            messages = [
                {
                    "role": "system", 
                    "content": "Gere um resumo estruturado da prova do ENADE CC 2017 com base nos documentos carregados."
                },
                {
                    "role": "user", 
                    "content": f"Documentos completos carregados. Gere um resumo com:\n"
                               "- Principais t√≥picos avaliados\n"
                               "- Distribui√ß√£o de quest√µes por √°rea\n"
                               "- An√°lise pedag√≥gica geral\n"
                               "Formato: Markdown com t√≠tulos"
                }
            ]
            
            resposta_parcial = ""
            container = st.empty()
            for chunk in deepseek_chat(
                messages=messages,
                api_key=api_key,
                model=model,
                temperature=0.1,  # Mais preciso
                max_tokens=1500
            ):
                if chunk:
                    resposta_parcial += chunk
                    container.markdown(resposta_parcial + "‚ñå")
            
            container.markdown(resposta_parcial)
            st.session_state.historico.append(("assistant", resposta_parcial))
            st.session_state.gerar_resumo = False

with tab2:
    st.header("An√°lise Pedag√≥gica das 35 Quest√µes")
    
    # Dados de exemplo (seriam extra√≠dos automaticamente na vers√£o final)
    dados_questoes = pd.DataFrame({
        'Quest√£o': [f"Q{i}" for i in range(1, 36)],
        'Tema Principal': [
            'Interpreta√ß√£o Gr√°fica', 'Agricultura Sustent√°vel', 'C√°lculo Energ√©tico',
            'Cr√≠tica de M√≠dia', 'Inova√ß√£o Agr√≠cola', 'Sociologia da Imigra√ß√£o',
            'Patrim√¥nio Cultural', 'ODS', 'Estruturas de Dados', 'Padr√µes de Projeto',
            'POO', 'Arquitetura', 'L√≥gica Digital',
            'Matem√°tica Discreta', 'Seguran√ßa Cibern√©tica',
            '√âtica Profissional', 'Tecnologia Educacional', 'Algoritmos',
            'Modelagem de Dados', 'Protocolos', 'L√≥gica Formal',
            'Otimiza√ß√£o', 'Teoria da Computa√ß√£o', 'Grafos',
            'Complexidade', 'Processamento Visual',
            'Renderiza√ß√£o', 'Gest√£o √Ågil', 'Ger√™ncia de Mem√≥ria',
            'An√°lise Sint√°tica', 'Concorr√™ncia', 'Sistemas Inteligentes',
            'Recursividade', 'Normaliza√ß√£o', 'Deadlock'
        ],
        '√Årea de Conhecimento': [
            'Matem√°tica', 'Sociedade', 'F√≠sica Aplicada',
            'Humanidades', 'Interdisciplinar', 'Sociedade',
            'Cultura', 'Sociedade', 'Algoritmos',
            'Eng. Software', 'Programa√ß√£o', 'Hardware',
            'Hardware', 'Matem√°tica', 'Redes',
            '√âtica', 'Educa√ß√£o', 'Algoritmos',
            'Banco de Dados', 'Redes', 'L√≥gica',
            'Algoritmos', 'Teoria', 'Algoritmos',
            'Algoritmos', 'Computa√ß√£o Gr√°fica',
            'Computa√ß√£o Gr√°fica', 'Eng. Software', 'Sistemas',
            'Compiladores', 'Sistemas', 'IA',
            'Algoritmos', 'Banco de Dados', 'Sistemas'
        ]
    })
    
    # An√°lise de distribui√ß√£o
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Total de Quest√µes", 35)
        st.metric("Quest√µes de Algoritmos", 8)
    with col2:
        st.metric("Quest√µes de Sociedade", 7)
        st.metric("Quest√µes de Sistemas", 6)
    
    st.dataframe(dados_questoes, height=500, use_container_width=True)
    
    # Filtros
    st.subheader("Filtrar Quest√µes")
    area_selecionada = st.selectbox("√Årea de Conhecimento", 
                                   options=['Todas'] + sorted(dados_questoes['√Årea de Conhecimento'].unique()))
    
    if area_selecionada != 'Todas':
        df_filtrado = dados_questoes[dados_questoes['√Årea de Conhecimento'] == area_selecionada]
        st.dataframe(df_filtrado, height=300)
        st.metric(f"Quest√µes de {area_selecionada}", len(df_filtrado))

with tab3:
    st.header("Sobre a An√°lise Integrada")
    st.markdown("""
    ### **Metodologia de An√°lise Combinada**
    O sistema utiliza os tr√™s documentos fundamentais em conjunto:
    1. **Prova Completa** - Base das quest√µes
    2. **Gabarito Oficial** - Respostas corretas
    3. **Padr√µes de Resposta** - Crit√©rios de avalia√ß√£o
    
    ### **Vantagens da Abordagem:**
    - üîó Contexto completo para an√°lise
    - üîç Maior precis√£o nas respostas
    - üìà Vis√£o pedag√≥gica integrada
    - ‚ö° Efici√™ncia na interpreta√ß√£o
    
    ### Fluxo de Processamento:
    ```mermaid
    graph TD
    A[Prova] --> C[Contexto Unificado]
    B[Gabarito] --> C
    D[Padr√µes] --> C
    C --> E{An√°lise Pedag√≥gica}
    E --> F[Chat Interativo]
    E --> G[Relat√≥rios]
    ```
    """)
    
    st.divider()
    st.subheader("Modelos DeepSeek Utilizados")
    st.markdown("""
    | Modelo | Contexto | Melhor Para | 
    |--------|----------|-------------|
    | **deepseek-chat** | 128K tokens | An√°lise geral e pedag√≥gica |
    | **deepseek-coder** | 128K tokens | Quest√µes t√©cnicas e de programa√ß√£o |
    """)

# Rodap√©
st.divider()
st.caption("Sistema Integrado ENADE CC 2017 | DAIA-INF| DeepSeek API 2025")