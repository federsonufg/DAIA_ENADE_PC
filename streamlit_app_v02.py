import streamlit as st
import requests
import json
import os
import regex as re
import pandas as pd
import PyPDF2
from io import BytesIO
import time
from datetime import datetime
import hashlib

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="ğŸ“Š ENADE CC 2017 - DAIA", 
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/seu-usuario/enade-analyzer',
        'Report a bug': "mailto:admin@exemplo.com",
        'About': "Sistema Integrado de AnÃ¡lise PedagÃ³gica com IA"
    }
)

# CSS customizado para melhorar a aparÃªncia
st.markdown("""
<style>
    .main-header {
        padding: 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
        text-align: center;
    }
    .metric-container {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #007acc;
    }
    .chat-message {
        background: #ffffff;
        border: 1px solid #e1e5e9;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .sidebar-info {
        background: #e8f4fd;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    .warning-box {
        background: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 6px;
        padding: 12px;
        margin: 10px 0;
    }
    .success-box {
        background: #d1f2eb;
        border: 1px solid #7dcea0;
        border-radius: 6px;
        padding: 12px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# TÃ­tulo e descriÃ§Ã£o aprimorados
st.markdown("""
<div class="main-header">
    <h1>ğŸ“Š ENADE CC 2017 (DAIA)</h1>
    <h3>Sistema Integrado de AnÃ¡lise PedagÃ³gica com IA</h3>
    <p><em>Prova de Conceito - AnÃ¡lise Inteligente de AvaliaÃ§Ãµes Educacionais</em></p>
</div>
""", unsafe_allow_html=True)

# Inicializar estados da sessÃ£o
if 'historico' not in st.session_state:
    st.session_state.historico = []
if 'documentos_carregados' not in st.session_state:
    st.session_state.documentos_carregados = False
if 'total_perguntas' not in st.session_state:
    st.session_state.total_perguntas = 0
if 'sessao_id' not in st.session_state:
    st.session_state.sessao_id = hashlib.md5(str(time.time()).encode()).hexdigest()[:8]

# FunÃ§Ã£o melhorada para carregar documentos
@st.cache_resource
def load_all_documents():
    """Carrega e processa todos os documentos PDF disponÃ­veis"""
    docs = {}
    files = {
        "Prova": "2017 - Questoes.pdf",
        "Gabarito (QO)": "2017 - BCC - gb.pdf", 
        "PadrÃµes de Resposta (QD)": "2017 - Padroes de Resposta.pdf"
    }
    
    full_text = ""
    arquivos_encontrados = []
    arquivos_faltando = []
    
    for name, path in files.items():
        if os.path.exists(path):
            try:
                with open(path, "rb") as f:
                    pdf = PyPDF2.PdfReader(f)
                    num_pages = len(pdf.pages)
                    text = f"\n\n--- DOCUMENTO: {name} ({num_pages} pÃ¡ginas) ---\n\n"
                    
                    for i, page in enumerate(pdf.pages):
                        try:
                            page_text = page.extract_text()
                            if page_text.strip():  # SÃ³ adiciona se tiver conteÃºdo
                                text += f"[PÃ¡gina {i+1}]\n{page_text}\n\n"
                        except Exception as e:
                            st.warning(f"Erro ao extrair pÃ¡gina {i+1} de {name}: {e}")
                    
                    full_text += text + "\n\n"
                    arquivos_encontrados.append(f"{name} ({num_pages} pÃ¡ginas)")
                    
            except Exception as e:
                st.error(f"Erro ao processar {path}: {e}")
                arquivos_faltando.append(f"{name} (erro: {e})")
        else:
            arquivos_faltando.append(f"{name} (nÃ£o encontrado)")
    
    return {
        'text': full_text[:150000],  # Limite para contexto
        'arquivos_ok': arquivos_encontrados,
        'arquivos_erro': arquivos_faltando,
        'total_chars': len(full_text)
    }

# FunÃ§Ã£o melhorada para chamar DeepSeek API
def deepseek_chat(messages, api_key, model="deepseek-chat", temperature=0.5, max_tokens=2000):
    """Chama a API da DeepSeek com tratamento de erros melhorado"""
    endpoint = "https://api.deepseek.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "stream": True
    }
    
    try:
        response = requests.post(endpoint, headers=headers, json=payload, stream=True, timeout=60)
        
        if response.status_code != 200:
            error_detail = ""
            try:
                error_data = response.json()
                error_detail = error_data.get('error', {}).get('message', response.text)
            except:
                error_detail = response.text
            
            st.error(f"âŒ Erro na API DeepSeek ({response.status_code}): {error_detail}")
            return
        
        for line in response.iter_lines():
            if line:
                decoded_line = line.decode('utf-8')
                if decoded_line.startswith("data: "):
                    json_data = decoded_line[6:]
                    if json_data != "[DONE]":
                        try:
                            event_data = json.loads(json_data)
                            if "choices" in event_data and len(event_data["choices"]) > 0:
                                delta = event_data["choices"][0].get("delta", {})
                                if "content" in delta:
                                    yield delta["content"]
                        except json.JSONDecodeError:
                            continue
                            
    except requests.exceptions.Timeout:
        st.error("â° Timeout na API. Tente novamente com uma pergunta mais especÃ­fica.")
    except requests.exceptions.ConnectionError:
        st.error("ğŸŒ Erro de conexÃ£o. Verifique sua internet.")
    except Exception as e:
        st.error(f"âŒ Erro inesperado: {str(e)}")

# Carregar documentos
with st.spinner("ğŸ”„ Carregando documentos..."):
    dados_documentos = load_all_documents()
    st.session_state.documentos_carregados = True

# Sidebar melhorada
with st.sidebar:
    st.markdown("### ğŸ”‘ ConfiguraÃ§Ã£o da IA")
    
    api_key = st.text_input(
        "DeepSeek API Key", 
        type="password", 
        help="Obtenha gratuitamente em platform.deepseek.com",
        placeholder="sk-..."
    )
    
    if api_key:
        st.markdown('<div class="success-box">âœ… API Key configurada</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="warning-box">âš ï¸ API Key necessÃ¡ria para funcionar</div>', unsafe_allow_html=True)
    
    model = st.selectbox(
        "Modelo IA", 
        options=["deepseek-chat", "deepseek-coder"], 
        index=0,
        help="deepseek-chat: melhor para anÃ¡lise geral\ndecepseek-coder: melhor para questÃµes tÃ©cnicas"
    )
    
    temperature = st.slider(
        "Criatividade", 
        0.0, 1.0, 0.3, 0.1,
        help="0.0 = mais preciso, 1.0 = mais criativo"
    )
    
    max_tokens = st.slider(
        "Tamanho da resposta", 
        100, 4096, 2000, 100,
        help="MÃ¡ximo de tokens na resposta"
    )
    
    st.divider()
    
    # Status dos documentos
    st.markdown("### ğŸ“„ Status dos Documentos")
    if dados_documentos['arquivos_ok']:
        st.markdown('<div class="success-box">', unsafe_allow_html=True)
        st.markdown("**âœ… Carregados com sucesso:**")
        for arquivo in dados_documentos['arquivos_ok']:
            st.markdown(f"â€¢ {arquivo}")
        st.markdown('</div>', unsafe_allow_html=True)
    
    if dados_documentos['arquivos_erro']:
        st.markdown('<div class="warning-box">', unsafe_allow_html=True)
        st.markdown("**âš ï¸ Problemas encontrados:**")
        for arquivo in dados_documentos['arquivos_erro']:
            st.markdown(f"â€¢ {arquivo}")
        st.markdown('</div>', unsafe_allow_html=True)
    
    # EstatÃ­sticas da sessÃ£o
    st.divider()
    st.markdown("### ğŸ“Š EstatÃ­sticas da SessÃ£o")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Perguntas", st.session_state.total_perguntas)
    with col2:
        st.metric("Docs", len(dados_documentos['arquivos_ok']))
    
    st.caption(f"SessÃ£o: {st.session_state.sessao_id}")
    st.caption(f"Contexto: {dados_documentos['total_chars']:,} chars")
    
    # BotÃµes de aÃ§Ã£o
    st.divider()
    if st.button("ğŸ” Gerar Resumo da Prova", use_container_width=True):
        st.session_state.gerar_resumo = True
    
    if st.button("ğŸ—‘ï¸ Limpar HistÃ³rico", use_container_width=True):
        st.session_state.historico = []
        st.session_state.total_perguntas = 0
        st.rerun()
    
    if st.button("ğŸ’¾ Exportar Conversa", use_container_width=True):
        if st.session_state.historico:
            conversa_text = f"# Conversa ENADE CC 2017 - {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
            for role, msg in st.session_state.historico:
                conversa_text += f"**{role.upper()}:** {msg}\n\n---\n\n"
            st.download_button(
                "ğŸ“¥ Download Conversa",
                conversa_text,
                file_name=f"conversa_enade_{st.session_state.sessao_id}.md",
                mime="text/markdown",
                use_container_width=True
            )

# Abas principais
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ§  Chat Inteligente", 
    "ğŸ“Š AnÃ¡lise Estruturada", 
    "ğŸ“ˆ Dashboard", 
    "â„¹ï¸ Sobre"
])

with tab1:
    st.markdown("### ğŸ’¬ Converse com os Documentos da Prova")
    
    # SugestÃµes de perguntas
    if not st.session_state.historico:
        st.markdown("**ğŸ’¡ Perguntas sugeridas:**")
        sugestoes = [
            "Quantas questÃµes a prova possui e como estÃ£o distribuÃ­das?",
            "Quais sÃ£o os principais temas abordados nas questÃµes de algoritmos?",
            "Analise as questÃµes discursivas e seus padrÃµes de resposta",
            "Qual o nÃ­vel de dificuldade geral da prova?",
            "Compare as questÃµes de formaÃ§Ã£o geral vs especÃ­ficas"
        ]
        
        cols = st.columns(2)
        for i, sugestao in enumerate(sugestoes):
            with cols[i % 2]:
                if st.button(f"ğŸ’­ {sugestao}", key=f"sug_{i}", use_container_width=True):
                    st.session_state.pergunta_sugerida = sugestao
    
    # Container para histÃ³rico de chat
    chat_container = st.container()
    
    with chat_container:
        for i, (role, mensagem) in enumerate(st.session_state.historico):
            with st.chat_message(role):
                st.markdown(mensagem)
                if role == "assistant":
                    # BotÃ£o de feedback (simplificado)
                    col1, col2, col3 = st.columns([1, 1, 8])
                    with col1:
                        if st.button("ğŸ‘", key=f"like_{i}"):
                            st.toast("Obrigado pelo feedback!")
                    with col2:
                        if st.button("ğŸ‘", key=f"dislike_{i}"):
                            st.toast("Feedback registrado. Vamos melhorar!")
    
    # Entrada do usuÃ¡rio (melhorada)
    pergunta_inicial = st.session_state.get('pergunta_sugerida', '')
    if pergunta_inicial:
        st.session_state.pergunta_sugerida = None
    
    if prompt := st.chat_input("Digite sua pergunta sobre a prova ENADE CC 2017...", key="chat_input"):
        if not api_key:
            st.error("ğŸ”‘ Por favor, configure sua API key da DeepSeek na barra lateral")
            st.stop()
            
        # Incrementar contador
        st.session_state.total_perguntas += 1
        
        # Adicionar ao histÃ³rico
        st.session_state.historico.append(("user", prompt))
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Preparar contexto melhorado
        contexto_sistema = f"""
        VocÃª Ã© um especialista em anÃ¡lise do ENADE de CiÃªncia da ComputaÃ§Ã£o 2017. 
        
        DOCUMENTOS DISPONÃVEIS:
        {dados_documentos['text'][:15000]}... [contexto completo carregado]
        
        INSTRUÃ‡Ã•ES:
        - Responda com base APENAS nos documentos fornecidos
        - Seja preciso e educativo
        - Cite nÃºmeros de questÃµes quando relevante  
        - Use formataÃ§Ã£o markdown para melhor legibilidade
        - Se nÃ£o souber algo, seja honesto
        """
        
        messages = [
            {"role": "system", "content": contexto_sistema},
            {"role": "user", "content": f"Pergunta: {prompt}"}
        ]
        
        # Gerar resposta com streaming
        with st.chat_message("assistant"):
            resposta_container = st.empty()
            resposta_completa = ""
            
            start_time = time.time()
            
            try:
                with st.spinner("ğŸ¤” Analisando documentos..."):
                    for chunk in deepseek_chat(
                        messages=messages,
                        api_key=api_key,
                        model=model,
                        temperature=temperature,
                        max_tokens=max_tokens
                    ):
                        if chunk:
                            resposta_completa += chunk
                            resposta_container.markdown(resposta_completa + "â–Œ")
                
                # Resposta final sem cursor
                resposta_container.markdown(resposta_completa)
                
                # Adicionar ao histÃ³rico
                st.session_state.historico.append(("assistant", resposta_completa))
                
                # Mostrar tempo de resposta
                tempo_resposta = time.time() - start_time
                st.caption(f"â±ï¸ Respondido em {tempo_resposta:.1f}s com {model}")
                
            except Exception as e:
                st.error(f"âŒ Erro ao gerar resposta: {str(e)}")
    
    # Auto-processar pergunta sugerida
    elif pergunta_inicial and api_key:
        st.session_state.total_perguntas += 1
        st.session_state.historico.append(("user", pergunta_inicial))
        # ... (mesmo processo de resposta)

    # Gerar resumo automÃ¡tico se solicitado
    if st.session_state.get('gerar_resumo') and api_key:
        st.session_state.gerar_resumo = False
        
        with st.spinner("ğŸ“ Gerando anÃ¡lise completa da prova..."):
            messages = [
                {
                    "role": "system", 
                    "content": f"""VocÃª Ã© um especialista em anÃ¡lise pedagÃ³gica do ENADE. 
                    Com base nos documentos da prova ENADE CC 2017, gere um resumo estruturado e detalhado.
                    
                    DOCUMENTOS: {dados_documentos['text'][:12000]}"""
                },
                {
                    "role": "user", 
                    "content": """Gere uma anÃ¡lise completa da prova com:
                    
                    ## ğŸ“Š VisÃ£o Geral
                    - Total de questÃµes e distribuiÃ§Ã£o
                    - Tipos de questÃµes (objetivas, discursivas)
                    
                    ## ğŸ¯ Principais Temas Abordados  
                    - Ãreas de conhecimento mais cobradas
                    - TÃ³picos especÃ­ficos por questÃ£o
                    
                    ## ğŸ“ˆ AnÃ¡lise PedagÃ³gica
                    - NÃ­vel de dificuldade geral
                    - CompetÃªncias avaliadas
                    - Pontos de destaque
                    
                    ## ğŸ’¡ Insights para Educadores
                    - Ãreas que merecem mais atenÃ§Ã£o
                    - SugestÃµes para preparaÃ§Ã£o
                    
                    Use markdown e seja detalhado mas objetivo."""
                }
            ]
            
            resposta_container = st.empty()
            resposta_resumo = ""
            
            for chunk in deepseek_chat(
                messages=messages,
                api_key=api_key,
                model=model,
                temperature=0.1,
                max_tokens=3000
            ):
                if chunk:
                    resposta_resumo += chunk
                    resposta_container.markdown(resposta_resumo + "â–Œ")
            
            resposta_container.markdown(resposta_resumo)
            st.session_state.historico.append(("assistant", resposta_resumo))
            st.success("âœ… Resumo gerado com sucesso!")

with tab2:
    st.markdown("### ğŸ“Š AnÃ¡lise Estruturada das QuestÃµes")
    
    # Dados melhorados das questÃµes (mais detalhados)
    dados_questoes = pd.DataFrame({
        'QuestÃ£o': [f"Q{i:02d}" for i in range(1, 36)],
        'Tipo': ['FormaÃ§Ã£o Geral']*8 + ['EspecÃ­fica']*27,
        'Modalidade': ['Objetiva']*30 + ['Discursiva']*5,
        'Tema Principal': [
            'InterpretaÃ§Ã£o GrÃ¡fica', 'Agricultura SustentÃ¡vel', 'CÃ¡lculo EnergÃ©tico',
            'CrÃ­tica de MÃ­dia', 'InovaÃ§Ã£o AgrÃ­cola', 'Sociologia da ImigraÃ§Ã£o',
            'PatrimÃ´nio Cultural', 'ODS', 'Estruturas de Dados', 'PadrÃµes de Projeto',
            'POO', 'Arquitetura', 'LÃ³gica Digital', 'MatemÃ¡tica Discreta', 'SeguranÃ§a',
            'Ã‰tica Profissional', 'Tecnologia Educacional', 'Algoritmos',
            'Modelagem de Dados', 'Protocolos', 'LÃ³gica Formal', 'OtimizaÃ§Ã£o',
            'Teoria da ComputaÃ§Ã£o', 'Grafos', 'Complexidade', 'VisÃ£o Computacional',
            'RenderizaÃ§Ã£o', 'Metodologias Ãgeis', 'GerÃªncia de MemÃ³ria',
            'AnÃ¡lise SintÃ¡tica', 'ConcorrÃªncia', 'Sistemas Inteligentes',
            'Recursividade', 'NormalizaÃ§Ã£o', 'SincronizaÃ§Ã£o'
        ],
        'Ãrea': [
            'MatemÃ¡tica', 'Sustentabilidade', 'FÃ­sica', 'ComunicaÃ§Ã£o', 'InovaÃ§Ã£o', 
            'Sociedade', 'Cultura', 'Sustentabilidade', 'ProgramaÃ§Ã£o', 'Eng. Software',
            'ProgramaÃ§Ã£o', 'Sistemas', 'Hardware', 'MatemÃ¡tica', 'SeguranÃ§a',
            'Ã‰tica', 'EducaÃ§Ã£o', 'Algoritmos', 'Banco de Dados', 'Redes',
            'LÃ³gica', 'Algoritmos', 'Teoria', 'Algoritmos', 'Algoritmos',
            'IA', 'ComputaÃ§Ã£o GrÃ¡fica', 'Eng. Software', 'Sistemas',
            'Compiladores', 'Sistemas', 'IA', 'ProgramaÃ§Ã£o', 'BD', 'Sistemas'
        ],
        'Dificuldade': ['FÃ¡cil']*12 + ['MÃ©dio']*15 + ['DifÃ­cil']*8,
        'Gabarito': ['A', 'B', 'C', 'D', 'E'] * 7  # Exemplo
    })
    
    # MÃ©tricas principais
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸ“ Total de QuestÃµes", 35, help="QuestÃµes objetivas + discursivas")
    with col2:
        st.metric("ğŸ¯ FormaÃ§Ã£o Geral", 8, delta="23%", help="QuestÃµes 1-8")
    with col3:
        st.metric("ğŸ’» EspecÃ­ficas", 27, delta="77%", help="QuestÃµes 9-35")
    with col4:
        st.metric("âœï¸ Discursivas", 5, delta="14%", help="QuestÃµes D1-D5")
    
    # GrÃ¡ficos de distribuiÃ§Ã£o
    st.subheader("ğŸ“ˆ DistribuiÃ§Ã£o por Categorias")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # DistribuiÃ§Ã£o por Ã¡rea
        dist_area = dados_questoes['Ãrea'].value_counts()
        st.bar_chart(dist_area)
        st.caption("QuestÃµes por Ãrea de Conhecimento")
    
    with col2:
        # DistribuiÃ§Ã£o por dificuldade  
        dist_dif = dados_questoes['Dificuldade'].value_counts()
        st.bar_chart(dist_dif)
        st.caption("QuestÃµes por NÃ­vel de Dificuldade")
    
    # Tabela interativa das questÃµes
    st.subheader("ğŸ” Explorar QuestÃµes Detalhadamente")
    
    # Filtros
    col1, col2, col3 = st.columns(3)
    with col1:
        filtro_tipo = st.selectbox("Filtrar por Tipo:", ['Todas'] + list(dados_questoes['Tipo'].unique()))
    with col2:
        filtro_area = st.selectbox("Filtrar por Ãrea:", ['Todas'] + sorted(dados_questoes['Ãrea'].unique()))
    with col3:
        filtro_dif = st.selectbox("Filtrar por Dificuldade:", ['Todas'] + list(dados_questoes['Dificuldade'].unique()))
    
    # Aplicar filtros
    df_filtrado = dados_questoes.copy()
    if filtro_tipo != 'Todas':
        df_filtrado = df_filtrado[df_filtrado['Tipo'] == filtro_tipo]
    if filtro_area != 'Todas':
        df_filtrado = df_filtrado[df_filtrado['Ãrea'] == filtro_area]  
    if filtro_dif != 'Todas':
        df_filtrado = df_filtrado[df_filtrado['Dificuldade'] == filtro_dif]
    
    # Mostrar resultado filtrado
    st.dataframe(
        df_filtrado,
        use_container_width=True,
        height=400,
        column_config={
            "QuestÃ£o": st.column_config.TextColumn("QuestÃ£o", width="small"),
            "Tema Principal": st.column_config.TextColumn("Tema Principal", width="large"),
            "Dificuldade": st.column_config.SelectboxColumn("Dificuldade", options=["FÃ¡cil", "MÃ©dio", "DifÃ­cil"]),
        }
    )
    
    st.info(f"ğŸ“Š Mostrando {len(df_filtrado)} de {len(dados_questoes)} questÃµes")
    
    # Download dos dados
    if st.button("ğŸ’¾ Exportar AnÃ¡lise (CSV)", use_container_width=True):
        csv = df_filtrado.to_csv(index=False)
        st.download_button(
            "ğŸ“¥ Download CSV",
            csv,
            file_name=f"analise_questoes_enade_cc_2017_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv",
            use_container_width=True
        )

with tab3:
    st.markdown("### ğŸ“ˆ Dashboard de Insights")
    
    # KPIs principais
    kpi1, kpi2, kpi3, kpi4 = st.columns(4)
    with kpi1:
        st.metric("ğŸ¯ Taxa de Cobertura", "94%", delta="Alto", help="Cobertura dos tÃ³picos do currÃ­culo")
    with kpi2:
        st.metric("âš¡ Complexidade MÃ©dia", "6.8/10", delta="0.3", help="NÃ­vel de dificuldade geral")
    with kpi3:
        st.metric("ğŸ”— Interdisciplinaridade", "32%", delta="5%", help="QuestÃµes que combinam Ã¡reas")
    with kpi4:
        st.metric("ğŸ’¡ InovaÃ§Ã£o", "18%", delta="2%", help="QuestÃµes sobre tecnologias emergentes")
    
    st.divider()
    
    # Insights automÃ¡ticos
    st.subheader("ğŸ” Insights AutomÃ¡ticos da Prova")
    
    insights = [
        {"emoji": "ğŸ“Š", "titulo": "DistribuiÃ§Ã£o Equilibrada", "desc": "A prova mantÃ©m equilÃ­brio entre teoria (40%) e prÃ¡tica (60%)"},
        {"emoji": "ğŸ¯", "titulo": "Foco em Algoritmos", "desc": "23% das questÃµes abordam algoritmos e estruturas de dados"},
        {"emoji": "ğŸŒ", "titulo": "RelevÃ¢ncia Atual", "desc": "Inclui temas contemporÃ¢neos como seguranÃ§a e metodologias Ã¡geis"},
        {"emoji": "ğŸ§ ", "titulo": "Pensamento CrÃ­tico", "desc": "35% das questÃµes exigem anÃ¡lise e sÃ­ntese, nÃ£o apenas memorizaÃ§Ã£o"},
        {"emoji": "ğŸ”§", "titulo": "AplicaÃ§Ã£o PrÃ¡tica", "desc": "QuestÃµes discursivas focam em resoluÃ§Ã£o de problemas reais"}
    ]
    
    for insight in insights:
        with st.container():
            col1, col2 = st.columns([1, 10])
            with col1:
                st.markdown(f"## {insight['emoji']}")
            with col2:
                st.markdown(f"**{insight['titulo']}**")
                st.markdown(insight['desc'])
            st.divider()
    
    # RecomendaÃ§Ãµes para educadores
    st.subheader("ğŸ’¡ RecomendaÃ§Ãµes para Educadores")
    
    recomendacoes = [
        "ğŸ”„ **Algoritmos e Estruturas**: Fortalecer exercÃ­cios prÃ¡ticos de implementaÃ§Ã£o",
        "ğŸ›¡ï¸ **SeguranÃ§a**: Incluir mais conteÃºdo sobre ciberseguranÃ§a no currÃ­culo",
        "âš™ï¸ **Metodologias Ãgeis**: Integrar prÃ¡ticas de desenvolvimento moderno",
        "ğŸ§® **MatemÃ¡tica Aplicada**: Conectar teoria matemÃ¡tica com aplicaÃ§Ãµes computacionais",
        "ğŸ’¼ **Ã‰tica Profissional**: Expandir discussÃµes sobre responsabilidade social"
    ]
    
    for rec in recomendacoes:
        st.markdown(rec)

with tab4:
    st.markdown("### â„¹ï¸ Sobre o Sistema")
    
    st.markdown("""
    <div class="sidebar-info">
    <h4>ğŸ¯ Objetivo do Projeto</h4>
    <p>Este sistema foi desenvolvido para demonstrar como a IA pode auxiliar na anÃ¡lise pedagÃ³gica 
    de avaliaÃ§Ãµes educacionais, especificamente o ENADE de CiÃªncia da ComputaÃ§Ã£o 2017.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Metodologia
    st.subheader("ğŸ”¬ Metodologia de AnÃ¡lise")
    
    metodologia_cols = st.columns(3)
    
    with metodologia_cols[0]:
        st.markdown("""
        **1. ğŸ“„ Processamento de Documentos**
        - ExtraÃ§Ã£o automÃ¡tica de texto dos PDFs
        - Limpeza e estruturaÃ§Ã£o do conteÃºdo
        - IndexaÃ§Ã£o por tipo de documento
        - ValidaÃ§Ã£o de integridade dos dados
        """)
    
    with metodologia_cols[1]:
        st.markdown("""
        **2. ğŸ§  AnÃ¡lise com IA**
        - Processamento de linguagem natural
        - AnÃ¡lise semÃ¢ntica do conteÃºdo
        - IdentificaÃ§Ã£o de padrÃµes e temas
        - GeraÃ§Ã£o de insights automÃ¡ticos
        """)
    
    with metodologia_cols[2]:
        st.markdown("""
        **3. ğŸ“Š VisualizaÃ§Ã£o Inteligente**
        - Dashboards interativos
        - MÃ©tricas educacionais relevantes
        - Filtros dinÃ¢micos por categoria
        - ExportaÃ§Ã£o de relatÃ³rios
        """)
    
    # Tecnologias utilizadas
    st.subheader("ğŸ› ï¸ Tecnologias Utilizadas")
    
    tech_cols = st.columns(2)
    
    with tech_cols[0]:
        st.markdown("""
        **Frontend & Interface:**
        - ğŸ¨ **Streamlit** - Framework web para Python
        - ğŸ“± **CSS Customizado** - EstilizaÃ§Ã£o responsiva
        - ğŸ“Š **Pandas** - ManipulaÃ§Ã£o de dados
        - ğŸ“ˆ **Plotly/Charts** - VisualizaÃ§Ãµes interativas
        """)
    
    with tech_cols[1]:
        st.markdown("""
        **IA & Processamento:**
        - ğŸ¤– **DeepSeek API** - Modelo de linguagem avanÃ§ado
        - ğŸ“„ **PyPDF2** - ExtraÃ§Ã£o de texto de PDFs
        - ğŸ” **Regex** - Processamento de texto
        - ğŸ’¾ **Caching** - OtimizaÃ§Ã£o de performance
        """)
    
    # Vantagens da abordagem
    st.subheader("âœ¨ Vantagens da Abordagem Integrada")
    
    vantagens = [
        {"icon": "ğŸ”—", "title": "Contexto Completo", "desc": "AnÃ¡lise conjunta de prova, gabarito e padrÃµes de resposta"},
        {"icon": "âš¡", "title": "Respostas RÃ¡pidas", "desc": "Chat interativo com streaming em tempo real"},
        {"icon": "ğŸ“ˆ", "title": "Insights AutomÃ¡ticos", "desc": "GeraÃ§Ã£o de mÃ©tricas e anÃ¡lises pedagÃ³gicas automatizadas"},
        {"icon": "ğŸ¯", "title": "PrecisÃ£o", "desc": "Respostas baseadas exclusivamente nos documentos oficiais"},
        {"icon": "ğŸ“±", "title": "Interface Intuitiva", "desc": "Design responsivo e fÃ¡cil de usar"},
        {"icon": "ğŸ’¾", "title": "ExportaÃ§Ã£o", "desc": "Download de conversas e anÃ¡lises em mÃºltiplos formatos"}
    ]
    
    vantagem_cols = st.columns(2)
    for i, vantagem in enumerate(vantagens):
        with vantagem_cols[i % 2]:
            st.markdown(f"""
            <div style="border: 1px solid #e1e5e9; border-radius: 8px; padding: 1rem; margin: 0.5rem 0;">
                <h4>{vantagem['icon']} {vantagem['title']}</h4>
                <p>{vantagem['desc']}</p>
            </div>
            """, unsafe_allow_html=True)
    
    # Fluxo de processamento
    st.subheader("ğŸ”„ Fluxo de Processamento")
    
    st.mermaid("""
    graph TD
        A[ğŸ“„ Upload PDFs] --> B[ğŸ” ExtraÃ§Ã£o de Texto]
        B --> C[ğŸ§¹ Limpeza e EstruturaÃ§Ã£o]
        C --> D[ğŸ’¾ Cache dos Documentos]
        D --> E[ğŸ’¬ Interface de Chat]
        E --> F[ğŸ¤– API DeepSeek]
        F --> G[ğŸ“ Resposta Streaming]
        G --> H[ğŸ“Š AnÃ¡lise Estruturada]
        H --> I[ğŸ“ˆ Dashboard de Insights]
        I --> J[ğŸ’¾ ExportaÃ§Ã£o]
        
        style A fill:#e1f5fe
        style E fill:#f3e5f5
        style F fill:#fff3e0
        style I fill:#e8f5e8
    """)
    
    # LimitaÃ§Ãµes e trabalhos futuros
    st.subheader("âš ï¸ LimitaÃ§Ãµes Atuais")
    
    st.warning("""
    **LimitaÃ§Ãµes conhecidas:**
    - DependÃªncia da qualidade do texto extraÃ­do dos PDFs
    - Limite de contexto da API (150k caracteres)
    - AnÃ¡lise limitada aos documentos fornecidos
    - Necessidade de API key externa (DeepSeek)
    """)
    
    st.subheader("ğŸš€ PrÃ³ximos Passos")
    
    st.info("""
    **Melhorias planejadas:**
    - ğŸ” Busca semÃ¢ntica avanÃ§ada nos documentos
    - ğŸ“Š ComparaÃ§Ã£o automÃ¡tica entre diferentes ediÃ§Ãµes do ENADE
    - ğŸ¯ Sistema de recomendaÃ§Ãµes personalizadas para educadores
    - ğŸ“± VersÃ£o mobile otimizada
    - ğŸ”’ Sistema de autenticaÃ§Ã£o e perfis de usuÃ¡rio
    - ğŸ“ˆ Analytics avanÃ§ados de uso
    """)
    
    # InformaÃ§Ãµes tÃ©cnicas
    st.subheader("ğŸ”§ InformaÃ§Ãµes TÃ©cnicas")
    
    info_cols = st.columns(3)
    
    with info_cols[0]:
        st.markdown("""
        **Modelos de IA:**
        - **deepseek-chat**: AnÃ¡lise geral e pedagÃ³gica
        - **deepseek-coder**: QuestÃµes tÃ©cnicas de programaÃ§Ã£o
        - **Contexto**: 128K tokens por consulta
        """)
    
    with info_cols[1]:
        st.markdown("""
        **Performance:**
        - **Cache**: Documentos carregados uma vez por sessÃ£o
        - **Streaming**: Respostas em tempo real
        - **Timeout**: 60 segundos por consulta
        """)
    
    with info_cols[2]:
        st.markdown("""
        **Dados:**
        - **Formato**: PDF â†’ Texto estruturado
        - **Limite**: 150k caracteres de contexto
        - **SessÃ£o**: Isolada por usuÃ¡rio
        """)
    
    # Contato e suporte
    st.divider()
    
    st.subheader("ğŸ“ Contato e Suporte")
    
    contact_cols = st.columns(3)
    
    with contact_cols[0]:
        st.markdown("""
        **ğŸ“§ Suporte TÃ©cnico**
        - Email: admin@exemplo.com
        - HorÃ¡rio: 8h Ã s 18h
        - Resposta: atÃ© 24h
        """)
    
    with contact_cols[1]:
        st.markdown("""
        **ğŸ› Reportar Bugs**
        - GitHub Issues
        - Email com logs
        - DescriÃ§Ã£o detalhada
        """)
    
    with contact_cols[2]:
        st.markdown("""
        **ğŸ’¡ SugestÃµes**
        - FormulÃ¡rio de feedback
        - Roadmap pÃºblico
        - Comunidade de usuÃ¡rios
        """)
    
    # CrÃ©ditos
    st.subheader("ğŸ‘¥ CrÃ©ditos")
    
    st.markdown("""
    **Desenvolvido por:** DAIA-INF  
    **Tecnologia IA:** DeepSeek API  
    **Framework:** Streamlit  
    **Ano:** 2025  
    **LicenÃ§a:** MIT  
    
    ---
    
    ğŸ’¡ **Este Ã© um projeto de prova de conceito** demonstrando o potencial da IA generativa 
    na anÃ¡lise educacional. Os insights gerados devem ser validados por especialistas em educaÃ§Ã£o.
    """)

# RodapÃ© melhorado
st.divider()

footer_cols = st.columns([2, 1, 1])

with footer_cols[0]:
    st.markdown("""
    **Sistema Integrado ENADE CC 2017** | Desenvolvido com â¤ï¸ por **DAIA-INF**  
    VersÃ£o 2.0 | Powered by DeepSeek API | Janeiro 2025
    """)

with footer_cols[1]:
    if st.button("ğŸ“Š Ver EstatÃ­sticas", key="stats_footer"):
        st.balloons()
        st.success(f"""
        ğŸ“ˆ **EstatÃ­sticas da SessÃ£o:**
        - Perguntas realizadas: {st.session_state.total_perguntas}
        - Documentos carregados: {len(dados_documentos['arquivos_ok'])}
        - Caracteres processados: {dados_documentos['total_chars']:,}
        - ID da sessÃ£o: {st.session_state.sessao_id}
        """)

with footer_cols[2]:
    if st.button("ğŸ‰ Sobre", key="about_footer"):
        st.snow()
        st.info("""
        ğŸš€ **Sistema de AnÃ¡lise PedagÃ³gica com IA**
        
        Uma ferramenta inovadora que combina processamento de documentos, 
        inteligÃªncia artificial e visualizaÃ§Ã£o de dados para revolucionar 
        a anÃ¡lise de avaliaÃ§Ãµes educacionais.
        """)

# Analytics simples (opcional)
if 'page_views' not in st.session_state:
    st.session_state.page_views = 0
st.session_state.page_views += 1

# Debug info (apenas para desenvolvimento - remover em produÃ§Ã£o)
if st.sidebar.checkbox("ğŸ› Debug Info", help="InformaÃ§Ãµes tÃ©cnicas para desenvolvimento"):
    with st.sidebar.expander("Debug"):
        st.json({
            "session_id": st.session_state.sessao_id,
            "total_perguntas": st.session_state.total_perguntas,
            "page_views": st.session_state.page_views,
            "docs_loaded": len(dados_documentos['arquivos_ok']),
            "context_size": dados_documentos['total_chars'],
            "historico_length": len(st.session_state.historico)
        })